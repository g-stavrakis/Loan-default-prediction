{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497b19e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:42.436182Z",
     "start_time": "2021-11-30T11:33:42.421218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadca914",
   "metadata": {},
   "source": [
    "# Creating Prediction Model based on existing Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762279b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:42.628346Z",
     "start_time": "2021-11-30T11:33:42.438181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the training data\n",
    "\n",
    "df = pd.read_csv('Credit_data.csv')\n",
    "df.T.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4a6f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:42.752132Z",
     "start_time": "2021-11-30T11:33:42.630514Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspecting the data\n",
    "\n",
    "print(df.shape)\n",
    "print('----------------')\n",
    "print(df.describe())\n",
    "print('----------------')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33cf499",
   "metadata": {},
   "source": [
    "## Pre-prossesing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f973dbe",
   "metadata": {},
   "source": [
    "- After inspection in the data it can be noticed that in the column EDUCATION the values for Unknown info are represented with 3 different numbers: 0,5,6. In order to reduce the number of categories the values of 5 and 6 were replaced by 0.\n",
    "- Also the column SEX provides a binary information about the Gender of the client, taking Values 1, 2. In order for the values to be in range 0 to 1 without losing any information, the value 1 was subtracted. Now, Males are represented with 0 and Females with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b631c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:42.767129Z",
     "start_time": "2021-11-30T11:33:42.754127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replacing the values of 5,6 in Education column with 0 because they denote the same Unknown info \n",
    "\n",
    "print('Before replace:' , df['EDUCATION'].unique())\n",
    "df['EDUCATION'].replace({5 : 0, 6 : 0}, inplace=True)\n",
    "print('After replace:', df['EDUCATION'].unique())\n",
    "\n",
    "# Making the values of Sex 0 and 1\n",
    "print('Before reduction:' , df['SEX'].unique())\n",
    "df['SEX'] = df['SEX']- 1\n",
    "print('After reduction:', df['SEX'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34461d",
   "metadata": {},
   "source": [
    "In columns PAY_1 to PAY_6 represented the repayment status of each client from 1 to 6 months prior to October respectively. It can be seen that the values from -2 to 0 represent different categories of clients and form 1 to 9 represent the months that a client delay hos payments. To separate then the categorical values from the numerical, two new columns were created for each column PAY.\n",
    "- PAY_CATEGORY represents the same categorical values from -2 to 0. In addition, a new category was add from the clients that were delayed. These clients are represented with the value of 1.\n",
    "- DELAY represents the months of delay for each client, captured by the numerical values from 1 to 9. Moreover, the value 0 was added for the non - delayed clients (with values -2, -1, 0).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd76eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:42.908188Z",
     "start_time": "2021-11-30T11:33:42.770130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separating the categorical, and numirical values in columns PAY\n",
    "\n",
    "for i in range(1,7):\n",
    "    column = 'PAY_'+str(i)\n",
    "    ncol = 'DELAY_'+str(i)\n",
    "\n",
    "    col_num = df[column]\n",
    "    col_num = col_num.replace({-2: 0, -1: 0})\n",
    "    NUM = pd.DataFrame(list(col_num), columns=[ncol])\n",
    "    col_cat = df[column]\n",
    "    col_cat = col_cat.replace({2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1})\n",
    "    CAT = pd.DataFrame(list(col_cat), columns=[column+'_CATEGORY'])\n",
    "    if i==1:\n",
    "        dfNew = pd.concat([NUM,CAT], axis=1)\n",
    "    else:\n",
    "        temp = pd.concat([NUM,CAT], axis=1)\n",
    "        dfNew = pd.concat([dfNew, temp], axis=1)\n",
    "\n",
    "df = pd.concat([df, dfNew], axis=1)\n",
    "df = df.drop(['PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e36b85",
   "metadata": {},
   "source": [
    "- For the columns having more than two or more categorical values, dummy variables were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97545a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:42.971924Z",
     "start_time": "2021-11-30T11:33:42.909916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Dummies for categorical variables\n",
    "\n",
    "df = pd.get_dummies(df,drop_first=True,columns=['EDUCATION','MARRIAGE'])\n",
    "df = pd.get_dummies(df,drop_first=True,columns=['PAY_1_CATEGORY','PAY_2_CATEGORY','PAY_3_CATEGORY',\n",
    "                                                'PAY_4_CATEGORY','PAY_5_CATEGORY','PAY_6_CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db54889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:42.987916Z",
     "start_time": "2021-11-30T11:33:42.973914Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142dec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:43.019913Z",
     "start_time": "2021-11-30T11:33:42.991914Z"
    }
   },
   "outputs": [],
   "source": [
    "# Searching for missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4e911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T10:44:28.107209Z",
     "start_time": "2021-11-29T10:44:28.093176Z"
    }
   },
   "source": [
    "- One of the basic assumptions that must be met for logistic regression is the absence of multicollinearity. For these reason highly correlated features need to be excluded from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138dc724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:48.939917Z",
     "start_time": "2021-11-30T11:33:43.023957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for high correlation between the variables\n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "mask = np.zeros_like(correlation_matrix, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, mask=mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43e6bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:48.955880Z",
     "start_time": "2021-11-30T11:33:48.943878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Excluding highly correlated Variables\n",
    "\n",
    "ex_var = ['BILL_AMT2','BILL_AMT4','BILL_AMT6','BILL_AMT3',\n",
    "          'MARRIAGE_2','PAY_2_CATEGORY_1','PAY_3_CATEGORY_1',\n",
    "          'PAY_6_CATEGORY_1','PAY_4_CATEGORY_1','PAY_5_CATEGORY_1',\n",
    "          'BILL_AMT6','BILL_AMT5','PAY_1_CATEGORY_1','PAY_2_CATEGORY_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef75a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:48.971923Z",
     "start_time": "2021-11-30T11:33:48.957881Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = df.drop(ex_var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f6402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.016719Z",
     "start_time": "2021-11-30T11:33:48.973878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking if there is any high correlation between the variables after the exclution.\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "correlation_matrix = temp.corr()\n",
    "\n",
    "mask = np.zeros_like(correlation_matrix, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, mask=mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97710d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.031765Z",
     "start_time": "2021-11-30T11:33:53.017724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Updating the dataset \n",
    "df = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdc077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.158723Z",
     "start_time": "2021-11-30T11:33:53.034770Z"
    }
   },
   "outputs": [],
   "source": [
    "df.T.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a775c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T10:48:53.469702Z",
     "start_time": "2021-11-29T10:48:53.343739Z"
    }
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51ffd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.174720Z",
     "start_time": "2021-11-30T11:33:53.160726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taking as indepentent variables all the Variables exept from ID and defualt_0\n",
    "\n",
    "Y = df[['default_0']]\n",
    "X = df.drop(['ID','default_0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35f947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.206723Z",
     "start_time": "2021-11-30T11:33:53.176725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spliting the data to test set and other (test 20%)\n",
    "TrainX, OtherX, TrainY, OtherY = train_test_split(X,Y, test_size=0.40, random_state=567)\n",
    "\n",
    "# Spliting the data to training and validation set \n",
    "ValidationX, TestX, ValidationY, TestY = train_test_split(OtherX, OtherY, test_size=0.50, random_state=567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b32c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.222794Z",
     "start_time": "2021-11-30T11:33:53.209724Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Percentage of Default in the Train set:', np.count_nonzero(TrainY)/len(TestY)) \n",
    "print('Percentage of Default in the Validation set:', np.count_nonzero(ValidationY)/len(TestY)) \n",
    "print('Percentage of Default in the Test set:', np.count_nonzero(TestY)/len(TestY)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fb7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.254718Z",
     "start_time": "2021-11-30T11:33:53.227721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing the columns for the continuous Variables\n",
    "\n",
    "col_norm = ['LIMIT_BAL', 'AGE', 'PAY_AMT1', 'PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6',\n",
    "             'BILL_AMT1','DELAY_1','DELAY_2','DELAY_3','DELAY_4','DELAY_5','DELAY_6']\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "TrainX[col_norm] = scaler.fit_transform(TrainX[col_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829a4a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.333766Z",
     "start_time": "2021-11-30T11:33:53.258724Z"
    }
   },
   "outputs": [],
   "source": [
    "TrainX.T.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1edc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.570721Z",
     "start_time": "2021-11-30T11:33:53.335724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the training set in the Logistic Regression \n",
    "\n",
    "logr = LogisticRegression(max_iter=1000).fit(TrainX, TrainY.values.ravel())\n",
    "print(\"The model's Coefficients are:\", logr.coef_)\n",
    "print(\"The model's R^2 is:\", logr.score(TrainX, TrainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c4986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.602758Z",
     "start_time": "2021-11-30T11:33:53.573721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing the columns with different orders of magnitude in the validation set \n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "ValidationX[col_norm] = scaler.fit_transform(ValidationX[col_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50695912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.634724Z",
     "start_time": "2021-11-30T11:33:53.606742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating the probabilities based on the validation set\n",
    "\n",
    "Y_probs = logr.predict_proba(ValidationX)[:,1]\n",
    "Y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edcaab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:53.808718Z",
     "start_time": "2021-11-30T11:33:53.636761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the ROC curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(ValidationY, Y_probs)\n",
    "\n",
    "# Dispaying the ROC curve\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(fpr, tpr, linewidth=3)\n",
    "plt.show()\n",
    "\n",
    "# Finding the AUC score of the curve\n",
    "\n",
    "AUC = roc_auc_score(ValidationY, Y_probs)\n",
    "print('The AUC score of the ROC curve is:', AUC) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742da7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T10:48:54.494803Z",
     "start_time": "2021-11-29T10:48:54.480800Z"
    }
   },
   "source": [
    "## Selecting a Threshold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298e6c8",
   "metadata": {},
   "source": [
    "Due to the description of the assignment it can be seen that the predictions of the model had an economic impact on the bank. More specifically:\n",
    "- For each new applicant that receive the credit and repaid in full the bank gains £1.500.  \n",
    "- For each new applicant that receive the credit and failed to repaid default the bank losses £5000. \n",
    "\n",
    "Based on these info, the profit for each threshold can be calculated and the threshold that maximize that profits need to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca58ffb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:55.135914Z",
     "start_time": "2021-11-30T11:33:53.810719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the thresholds that maximize the profits\n",
    "\n",
    "prof=[]\n",
    "for thres in thresholds:\n",
    "    \n",
    "    # Find the predictions upper of these theshold\n",
    "    Y_pred = np.where(Y_probs > thres, 1, 0)\n",
    "    cm = confusion_matrix(ValidationY,Y_pred)\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "    accur = (TN+TP)/(TN+TP+FN+TP)\n",
    "    sens = (TP)/(TP+FN)\n",
    "    spec = (TN)/(TN+FP)\n",
    "    prec = (TP)/ (TP+FP)\n",
    "    # Calculate the profit for these thresholds \n",
    "    profit= TN*1500 + FP*0 - FN*5000 + TP*0\n",
    "    prof.append([thres, profit, accur, sens, spec, prec])\n",
    "\n",
    "# Sorting the data based on thershold in order to visualisise\n",
    "prof.sort(key = lambda x: x[0])\n",
    "thres_df = pd.DataFrame(prof, columns=['Threshold','Profit','Accuracy','Sensitivity','Specificity','Precision'])\n",
    "thres_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef178e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:55.501235Z",
     "start_time": "2021-11-30T11:33:55.137928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the profits along with Accuracy, Sensitivity and Specificity for each threshold\n",
    "\n",
    "fig1 = plt.figure(figsize=(12,5))\n",
    "ax1 = fig1.add_subplot(1,2,1)\n",
    "ax2 = fig1.add_subplot(1,2,2)\n",
    "thres_df.plot.line(x='Threshold', y=['Profit'], ax=ax1)\n",
    "thres_df.plot.line(x='Threshold' ,y=['Accuracy','Sensitivity','Specificity'], ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43f91a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:55.532287Z",
     "start_time": "2021-11-30T11:33:55.507257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choosing the threshold that generate the most profit\n",
    "\n",
    "prof.sort(key = lambda x: x[1], reverse=True)\n",
    "chosen_threshold = prof[0][0]\n",
    "print(chosen_threshold)\n",
    "threshold_idx = np.where(thresholds == chosen_threshold)[0][0]\n",
    "print(threshold_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c1347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:55.547285Z",
     "start_time": "2021-11-30T11:33:55.534247Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the FPR and TPR for this Threshold:\n",
    "print(\"At threshold  \" + str(thresholds[threshold_idx]))\n",
    "print(\"the False Positive rate is \" + str(fpr[threshold_idx]))\n",
    "print(\"the True Positive rate is \" + str(tpr[threshold_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b5208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:55.769697Z",
     "start_time": "2021-11-30T11:33:55.555249Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding the predictions based on chosen threshold\n",
    "Y_pred = np.where(Y_probs > chosen_threshold, 1, 0)\n",
    "# Creating the confusion matrix\n",
    "cm = confusion_matrix(ValidationY,Y_pred)\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Visualizing the Confusion Matrix\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.ylabel('Actual Results')\n",
    "plt.xlabel('Predicted Results')\n",
    "ax1.xaxis.set_label_position(\"top\")\n",
    "\n",
    "profits = TN*1500 + FP*0 - FN*5000 + TP*0\n",
    "\n",
    "print(\"At Threshold:\", chosen_threshold)\n",
    "print(\"Predicted Profit:\" ,\"£\",profits)\n",
    "print(\"Model's Accuracy:\", (TP+TN)/(TN+TP+FN+FP))\n",
    "print(\"Model's Misclassification:\", (FP+FN)/(TN+TP+FN+FP))\n",
    "print(\"Model's Specificity:\", TN/(FP+TN))\n",
    "print(\"Model's Sensitivity:\", TP/(TP+FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c559e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T11:01:35.191960Z",
     "start_time": "2021-11-29T11:01:35.191960Z"
    }
   },
   "source": [
    "## Retraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a09bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:55.801732Z",
     "start_time": "2021-11-30T11:33:55.773776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combining the validation and Training set to create new training set  \n",
    "\n",
    "trainX_final=pd.concat([TrainX, ValidationX])\n",
    "trainY_final=pd.concat([TrainY, ValidationY])\n",
    "\n",
    "print(trainX_final.shape)\n",
    "print(trainY_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e576e7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:55.833698Z",
     "start_time": "2021-11-30T11:33:55.807702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing the columns with different orders of magnitude in the testing set\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "TestX[col_norm] = scaler.fit_transform(TestX[col_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab844e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.228694Z",
     "start_time": "2021-11-30T11:33:55.839738Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrainong the model with the final training set\n",
    "\n",
    "logr_final = LogisticRegression(max_iter=1000).fit(trainX_final, trainY_final.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1764252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.243696Z",
     "start_time": "2021-11-30T11:33:56.229694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing the model to the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9defe701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.259696Z",
     "start_time": "2021-11-30T11:33:56.246699Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating the probabilities based on the test set\n",
    "Y_test_probs=logr_final.predict_proba(TestX)[:,1]\n",
    "# Assigning the selected threshold\n",
    "threshold = chosen_threshold\n",
    "# Predicting the values of Y\n",
    "Y_test_pred=np.where(Y_test_probs > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cb0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.419259Z",
     "start_time": "2021-11-30T11:33:56.261710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(TestY, Y_test_probs)\n",
    "\n",
    "# Dispaying the ROC curve\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(fpr, tpr, linewidth=3)\n",
    "plt.show()\n",
    "\n",
    "# Finding the AUC score of the curve\n",
    "AUC = roc_auc_score(TestY, Y_test_probs)\n",
    "print('The AUC score of the ROC curve is:', AUC)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6199f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.609302Z",
     "start_time": "2021-11-30T11:33:56.421262Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the confusion matrix\n",
    "cm = confusion_matrix(TestY,Y_test_pred)\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Visualizing the Confusion Matrix\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.ylabel('Actual Results')\n",
    "plt.xlabel('Predicted Results')\n",
    "ax1.xaxis.set_label_position(\"top\")\n",
    "\n",
    "profits = TN*1500 + FP*0 - FN*5000 + TP*0\n",
    "\n",
    "print(\"At Threshold:\", chosen_threshold)\n",
    "print(\"Predicted Profit:\" ,\"£\",profits)\n",
    "print(\"Model's Accuracy:\", (TP+TN)/(TN+TP+FN+FP))\n",
    "print(\"Model's Misclassification:\", (FP+FN)/(TN+TP+FN+FP))\n",
    "print(\"Model's Specificity:\", TN/(FP+TN))\n",
    "print(\"Model's Sensitivity:\", TP/(TP+FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3477b9",
   "metadata": {},
   "source": [
    "# Using the Model on New Applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c33c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.687301Z",
     "start_time": "2021-11-30T11:33:56.610302Z"
    }
   },
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('New_applicantions.csv')\n",
    "df_real.T.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cff50",
   "metadata": {},
   "source": [
    "## Pre-prossesing the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672da159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.703262Z",
     "start_time": "2021-11-30T11:33:56.688262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop Unnamed: 24 column\n",
    "df_real.drop(['Unnamed: 24'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b99fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.719264Z",
     "start_time": "2021-11-30T11:33:56.705263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the values of 5,6 in Education column with 0 because they denote the same Unknown info  \n",
    "print('Before replace:' , df_real['EDUCATION'].unique())\n",
    "df_real['EDUCATION'].replace({5 : 0, 6 : 0}, inplace=True)\n",
    "print('After replace:', df_real['EDUCATION'].unique())\n",
    "\n",
    "# Make the values of Sex 0 and 1\n",
    "print('Before reduction:' , df_real['SEX'].unique())\n",
    "df_real['SEX'] = df_real['SEX']- 1\n",
    "print('After reduction:', df_real['SEX'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702d85e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.767311Z",
     "start_time": "2021-11-30T11:33:56.721267Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1,7):\n",
    "    column = 'PAY_'+str(i)\n",
    "    ncol = 'DELAY_'+str(i)\n",
    "\n",
    "    col_num = df_real[column]\n",
    "    col_num = col_num.replace({-2: 0, -1: 0})\n",
    "    NUM = pd.DataFrame(list(col_num), columns=[ncol])\n",
    "    col_cat = df_real[column]\n",
    "    col_cat = col_cat.replace({2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1})\n",
    "    CAT = pd.DataFrame(list(col_cat), columns=[column+'_CATEGORY'])\n",
    "    if i==1:\n",
    "        dfNew = pd.concat([NUM,CAT], axis=1)\n",
    "    else:\n",
    "        temp = pd.concat([NUM,CAT], axis=1)\n",
    "        dfNew = pd.concat([dfNew, temp], axis=1)\n",
    "\n",
    "df_real = pd.concat([df_real, dfNew], axis=1)\n",
    "df_real = df_real.drop(['PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a36176a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.799626Z",
     "start_time": "2021-11-30T11:33:56.769262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Dummies for categorical variables\n",
    "df_real = pd.get_dummies(df_real,drop_first=True,columns=['EDUCATION','MARRIAGE'])\n",
    "df_real = pd.get_dummies(df_real,drop_first=True,columns=['PAY_1_CATEGORY','PAY_2_CATEGORY','PAY_3_CATEGORY',\n",
    "                                                'PAY_4_CATEGORY','PAY_5_CATEGORY','PAY_6_CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a4564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.814592Z",
     "start_time": "2021-11-30T11:33:56.800592Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_real.drop(['ID'],axis=1)\n",
    "X = X.drop(ex_var,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de16caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.845960Z",
     "start_time": "2021-11-30T11:33:56.816633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing the columns with different orders of magnitude in the real dataset \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X[col_norm] = scaler.fit_transform(X[col_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205e03f",
   "metadata": {},
   "source": [
    "## Predicting default clients in the New applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc6ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.893165Z",
     "start_time": "2021-11-30T11:33:56.847950Z"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd8333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.909522Z",
     "start_time": "2021-11-30T11:33:56.895179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating the probabilities based on the real set\n",
    "Y_test_probs=logr_final.predict_proba(X)[:,1]\n",
    "# Assigning the selected threshold\n",
    "threshold = chosen_threshold\n",
    "# Predicting the values of Y\n",
    "Y_test_pred=np.where(Y_test_probs > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbe17c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.939811Z",
     "start_time": "2021-11-30T11:33:56.912845Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43d89c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.955798Z",
     "start_time": "2021-11-30T11:33:56.942797Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of new applicants that defaulted:', np.count_nonzero(Y_test_pred), 'out of 1000.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfcd03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:56.971797Z",
     "start_time": "2021-11-30T11:33:56.957795Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating column for recomended client's for issuing credit\n",
    "\n",
    "Issue = []\n",
    "for i in Y_test_pred:\n",
    "    if i == 0: j=1\n",
    "    else: j=0\n",
    "    Issue.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337cde03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:57.003798Z",
     "start_time": "2021-11-30T11:33:56.975797Z"
    }
   },
   "outputs": [],
   "source": [
    "Issue = pd.DataFrame({'Issue_Credit': Issue})\n",
    "Issue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b259fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:57.019796Z",
     "start_time": "2021-11-30T11:33:57.006800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating new csv with only recomentadion\n",
    "\n",
    "Issue.to_csv('Recomendation_For_New_Applications.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40458d2",
   "metadata": {},
   "source": [
    "## Answering the Questions 2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa1bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:57.051800Z",
     "start_time": "2021-11-30T11:33:57.021796Z"
    }
   },
   "outputs": [],
   "source": [
    "Idx = [i+1 for i in range(len(Y_test_probs))]\n",
    "client_prob = pd.DataFrame({'Client_index': Idx, 'Prob_to_Default': Y_test_probs}) \n",
    "client_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06959c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T11:22:07.604643Z",
     "start_time": "2021-11-28T11:22:07.590633Z"
    }
   },
   "source": [
    "Question 2 - Which three of the 1,000 pilot clients are most likely to repay the loan if it were granted to them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f9016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:57.082796Z",
     "start_time": "2021-11-30T11:33:57.055803Z"
    }
   },
   "outputs": [],
   "source": [
    "best_clients = client_prob.sort_values('Prob_to_Default')\n",
    "best_clients.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495f946",
   "metadata": {},
   "source": [
    "Question 3 - Which three of 1,000 pilot clients are least likely to repay the loan if it were granted to them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381828e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T11:33:57.112795Z",
     "start_time": "2021-11-30T11:33:57.085803Z"
    }
   },
   "outputs": [],
   "source": [
    "best_clients.tail(3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "359a9d8540f91b69dadffbb31ef5c5902ecd7a0f48dbb2da0e5c59f396aacb7c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
